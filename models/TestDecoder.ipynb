{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "from models.decoder import *\n",
    "from models.cirtorch_network import init_network, extract_vectors\n",
    "from models.cirtorch_utils.genericdataset import ImagesFromList\n",
    "\n",
    "from common.scheduler import LearningRateScheduler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "resolution = 128\n",
    "overfit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir = init_network({'architecture' : 'resnet34'}).to(device)\n",
    "#dec = DecoderV1(input_size=512, out_res = resolution, start_channels=32, resolution_expansion_factor=6)\n",
    "dec = DecoderV2(input_size=512, out_res = resolution, start_res=10)\n",
    "#dec = OverfitDecoder(input_size=512, out_res=resolution)\n",
    "dec.to(device)\n",
    "summary(cir, (3, resolution, resolution))\n",
    "summary(dec, (512,), batch_size=8)\n",
    "if not 'losses' in locals() and not 'losses' in globals():\n",
    "    losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.loadtxt('../data/img_stats.txt')\n",
    "normalize = transforms.Normalize(\n",
    "   mean=stats[0],\n",
    "   std=stats[1]\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(resolution),\n",
    "    transforms.CenterCrop(resolution),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "images = ['db/{}.jpg'.format(i+1) for i in range(overfit)] #4479\n",
    "dataset = ImagesFromList('../data/AachenDayNight/images_upright', images=images, transform=transform, imsize=1024)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = min(overfit, batch_size), shuffle = False, num_workers=4)\n",
    "print('Using {} image(s) for training'.format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 900\n",
    "start_lr = 1e-3\n",
    "end_lr = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(list(cir.parameters()) + list(dec.parameters()), lr=start_lr)\n",
    "loss_fn = torch.nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_lr = lambda org_lr, log_range, epoch, total_epochs: org_lr*(1.-epoch/total_epochs)\n",
    "#new_lr = lambda org_lr, epoch, total_epochs: org_lr*(1.-epoch/total_epochs)/(epoch+1)\n",
    "#new_lr = lambda org_lr, log_range, epoch, total_epochs: np.power(10, -(-log(org_lr, 10)*np.exp(epoch/total_epochs)))\n",
    "#new_lr = lambda org_lr, log_range, epoch, total_epochs: np.power(10, -(log_range*(-np.cos(np.pi*(epoch/total_epochs))+1.)-log(org_lr, 10)-log_range))\n",
    "#new_lr = lambda start_lr, end_lr, epoch, total_epochs: np.power(10, (np.cos(np.pi*(epoch/total_epochs))/2.+.5)*abs(start_lr-end_lr) + end_lr)\n",
    "#new_lr = lambda start_lr, end_lr, epoch, total_epochs: np.power(10, ((end_lr-start_lr)/total_epochs)*epoch + start_lr)\n",
    "\n",
    "schedule = LearningRateScheduler(total_epochs, log(start_lr, 10), log(end_lr, 10), schedule_plan='log_cosine')\n",
    "\n",
    "x = np.arange(total_epochs)\n",
    "y = schedule.get_lr(x)\n",
    "plt.title('Learning rate schedule')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('learning rate (log scale)')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir.train()\n",
    "dec.train()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    epoch_losses = []\n",
    "    for i, data in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "        data = data.to(device)\n",
    "        x = cir(data)\n",
    "        x = dec(x)\n",
    "        loss = loss_fn(x, data)# Variable(data, requires_grad=False, device=device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        schedule.adjust_learning_rate(optim, epoch+float(i)/len(dataloader))\n",
    "    el = np.mean(epoch_losses)\n",
    "    losses.append(el)\n",
    "    #if epoch % 10 == 0:\n",
    "    print('\\rEpoch: {}\\tLoss: {:.2f}\\tLearning rate: {:.6f}'.format(epoch, el, schedule.get_lr(epoch)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.plot(losses)\n",
    "plt.xlim(0, len(losses))\n",
    "plt.ylim(1, max(losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_plt(img, stats=None):\n",
    "    img = img.cpu().detach().squeeze(0).permute(1, 2, 0).numpy()\n",
    "    if stats is not None:\n",
    "        img = stats[1]*img+stats[0]\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    return img\n",
    "\n",
    "cir.eval()\n",
    "dec.eval()\n",
    "test_data = dataset[0]\n",
    "recon = dec(cir(test_data.unsqueeze(0).to(device)))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "img = torch_to_plt(test_data, stats)\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_title('Input data')\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "img = torch_to_plt(recon, stats=stats)\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_title('Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfnet-pytorch",
   "language": "python",
   "name": "hfnet-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
