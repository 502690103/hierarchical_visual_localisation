{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image retrieval\n",
    "Based on [image retrieval approach by filip radenovic](https://github.com/filipradenovic/cnnimageretrieval-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.cirtorch_network import init_network, extract_vectors\n",
    "from dataset_loaders.txt_to_db import get_images, get_points\n",
    "from evaluate import get_files\n",
    "from dataset_loaders.utils import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('data/teacher_models/retrievalSfM120k-resnet101-gem-b80fb85.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params = {}\n",
    "net_params['architecture'] = state['meta']['architecture']\n",
    "net_params['pooling'] = state['meta']['pooling']\n",
    "net_params['local_whitening'] = state['meta'].get('local_whitening', False)\n",
    "net_params['regional'] = state['meta'].get('regional', False)\n",
    "net_params['whitening'] = state['meta'].get('whitening', False)\n",
    "net_params['mean'] = state['meta']['mean']\n",
    "net_params['std'] = state['meta']['std']\n",
    "net_params['pretrained'] = False\n",
    "# load network\n",
    "net = init_network(net_params)\n",
    "net.load_state_dict(state['state_dict'])\n",
    "if 'Lw' in state['meta']:\n",
    "    net.meta['Lw'] = state['meta']['Lw']\n",
    "print(net.meta_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the multi-scale parameters\n",
    "ms = list(eval('[1]'))\n",
    "if len(ms)>1 and net.meta['pooling'] == 'gem' and not net.meta['regional'] and not net.meta['whitening']:\n",
    "    msp = net.pool.p.item()\n",
    "    print(\">> Set-up multiscale:\")\n",
    "    print(\">>>> ms: {}\".format(ms))            \n",
    "    print(\">>>> msp: {}\".format(msp))\n",
    "else:\n",
    "    msp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()\n",
    "# set up the transform\n",
    "normalize = transforms.Normalize(\n",
    "    mean=net.meta['mean'],\n",
    "    std=net.meta['std']\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "Lw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'data/AachenDayNight/images_upright'\n",
    "image_names = [os.path.join(dataroot, img.name) for img in images.values()]\n",
    "augmented_names = [os.path.join('data/AachenDayNight/AugmentedNightImages_high_res', img.name.replace('.jpg', '.png').replace('db/', '')) for img in images.values()]\n",
    "query_image_names = get_files('data/AachenDayNight/images_upright/query', '*.jpg')\n",
    "\n",
    "im_size = 1024\n",
    "\n",
    "data_desc_path = 'data/cirtorch_data_descs.npy'\n",
    "augmented_desc_path = 'data/cirtorch_augmented_descs.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(data_desc_path):\n",
    "    print('Loading data from path', end='')\n",
    "    vecs = np.load(data_desc_path)\n",
    "    print('\\rData loaded')\n",
    "else:\n",
    "    vecs = extract_vectors(net, image_names, im_size, transform, ms=ms, msp=msp)\n",
    "    np.save(data_desc_path, vecs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(augmented_desc_path):\n",
    "    print('Loading data from path', end='')\n",
    "    vecs = np.load(augmented_desc_path)\n",
    "    print('\\rData loaded')\n",
    "else:\n",
    "    vecs = extract_vectors(net, augmented_names, im_size, transform, ms=ms, msp=msp)\n",
    "    np.save(augmented_desc_path, vecs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvecs = extract_vectors(net, query_image_names, im_size, transform, ms=ms, msp=msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = vecs.numpy()\n",
    "qvecs = qvecs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qvecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripletnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cirtorch_utils.genericdataset import PointCloudImagesFromList, PCDataLoader\n",
    "import models.pointnet2_classification as ptnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points3d = get_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/triplet_baseline_w_schedule_1/'\n",
    "#log_dir = 'logs/triplet_baseline_w_schedule_no_normalize/'\n",
    "epoch = 19\n",
    "trptnet = ptnet.NetAachen()\n",
    "trptnet.load_state_dict(torch.load(os.path.join(log_dir, 'ptnet_epoch_{:03d}.pth.tar'.format(epoch)))['model_state_dict'])\n",
    "trptnet.eval()\n",
    "trcnnet = init_network({'architecture' : 'resnet34'})\n",
    "trcnnet.load_state_dict(torch.load(os.path.join(log_dir, 'cnn2d_epoch_{:03d}.pth.tar'.format(epoch)))['model_state_dict'])\n",
    "trcnnet.eval()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.loadtxt('data/img_stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=stats[0],\n",
    "   std=stats[1]\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PointCloudImagesFromList('data/AachenDayNight/images_upright', images, points3d, imsize=1024, transform=transform, triplet=False, min_num_points=100)\n",
    "dataloader = PCDataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trptnet.to(device)\n",
    "trcnnet.to(device)\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_norm = lambda x: (x.transpose(0, 1) / torch.norm(x, p=2, dim=1)).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalculate = True\n",
    "\n",
    "if recalculate:\n",
    "    img_descs = []\n",
    "    point_cloud_descs = []\n",
    "    for i, data in enumerate(dataloader):\n",
    "        #fv1 = trcnnet(data[0].to(device)).detach().squeeze(0).cpu().numpy()\n",
    "        #fv2 = trptnet(data[1].to(device)).detach().cpu().squeeze(0).numpy()\n",
    "        fv1 = torch_norm(trcnnet(data[0].to(device)).unsqueeze(0)).detach().squeeze(0).cpu().numpy()\n",
    "        fv2 = torch_norm(trptnet(data[1].to(device))).detach().cpu().squeeze(0).numpy()\n",
    "        img_descs.append(fv1)\n",
    "        point_cloud_descs.append(fv2)\n",
    "        print('Difference: {:f}\\ttotal norm v1: {}, v2: {}'.format(np.dot(fv1, fv2), np.linalg.norm(fv1), np.linalg.norm(fv2)))\n",
    "        print('\\r{}/{}'.format(i+1, len(dataloader)), end='')\n",
    "        if i > 5:\n",
    "            break\n",
    "    print('')\n",
    "    img_descs = np.vstack(img_descs)\n",
    "    print(img_descs.shape)\n",
    "    np.save('data/triplet_img_descriptors.npy', img_descs)\n",
    "    point_cloud_descs = np.vstack(point_cloud_descs)\n",
    "    print(point_cloud_descs.shape)\n",
    "    np.save('data/triplet_pointnet_descriptors.npy', point_cloud_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    y = trcnnet(data[0].to(device)).detach()\n",
    "    x = trptnet(data[1].to(device)).detach()\n",
    "    break\n",
    "normalize = lambda x: (x.transpose(0, 1) / torch.norm(x, p=2, dim=1)).transpose(0,1)\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "print(x)\n",
    "#print(y)\n",
    "x = normalize(x)\n",
    "if len(y.size()) == 1:\n",
    "    y = y.unsqueeze(0)\n",
    "y = normalize(y)\n",
    "x = x.cpu().numpy()\n",
    "print(x.shape)\n",
    "print(np.linalg.norm(x))\n",
    "y = y.cpu().numpy()\n",
    "print(y.shape)\n",
    "print(np.linalg.norm(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfnet-pytorch",
   "language": "python",
   "name": "hfnet-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
